# Urdu_Sign_Interpreter
 Research shows that approximately 2 billion people worldwide are affected by some form of hearing impairment, and statistically, eight out of every 100 individuals are born mute. These individuals heavily rely on sign language for their daily communication. Consequently, during my fourth year of undergraduate studies, I initiated a startup with the mission of breaking down communication barriers between the deaf-mute community and the general population, aiming to be their voice. The startup offered an interpreter that translated Pakistan Sign Language, used by the deaf-mute community, into Urdu text and voice. This initiative garnered national-level recognition, and I had the opportunity to present it at international conferences.


Resultantly, itâ€™s An Android application that employs Image Processing and Machine Learning to instantly convert Sign Language into text. It captures the user's live signing movements and translates them into real-time text. Technologies applied in this project include Java, Python, OpenCV, Google Firebase, and TensorFlow.

